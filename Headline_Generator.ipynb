{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielaquaries20/TugasML_3/blob/main/Headline_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNLtVxQit2kE",
        "outputId": "47404a37-85a9-46d1-dce2-0b682d0b5fb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9335"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "nyt_dir = 'data/nyt_dataset/articles/'\n",
        "\n",
        "all_headlines = []\n",
        "for filename in os.listdir(nyt_dir):\n",
        "    if 'Articles' in filename:\n",
        "        # Read in all the data from the CSV file\n",
        "        headlines_df = pd.read_csv(nyt_dir + filename)\n",
        "        # Add all of the headlines to our list\n",
        "        all_headlines.extend(list(headlines_df.headline.values))\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6bz7-9nt2kG",
        "outputId": "e3c223f1-8a92-4f39-bf5c-88694dc9e394"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'Unknown',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'Unknown',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'Unknown',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZsyROcSt2kI",
        "outputId": "54715518-3422-4adc-b285-f67ca03e3f9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove all headlines with the value of \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8hYhepjt2kJ",
        "outputId": "7e6a599a-9ea3-4135-bf07-ad8c4bdee698"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too',\n",
              " 'Is the dream in Australia crumbling?',\n",
              " 'Police in Texas Change Account in Officer’s Fatal Shooting of 15-Year-Old',\n",
              " 'Most Adults Favor Sex Ed. Most Students Don’t Get It.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR1AONq9t2kL",
        "outputId": "396f9eab-5e9d-4b56-87dc-30728f5f0b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words:  11753\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Tokenize the words in our headlines\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_headlines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3imqI6A7t2kN",
        "outputId": "e42f1809-a9f5-4d3f-dfc3-b190acc258d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'a': 2, 'plan': 82, 'man': 139, 'panama': 2732, 'canal': 7047}\n"
          ]
        }
      ],
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\n",
        "print(subset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdQWBNrut2kO",
        "outputId": "3a94019a-63a4-4844-d1ea-31117ce729f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2], [139], [2], [82], [2], [7047], [2732]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHilUdqvt2kO",
        "outputId": "df33ddae-ccad-4e74-a389-22af6fa0c9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my beijing', 'my beijing the', 'my beijing the sacred', 'my beijing the sacred city', '6 million']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[52, 1616],\n",
              " [52, 1616, 1],\n",
              " [52, 1616, 1, 1992],\n",
              " [52, 1616, 1, 1992, 125],\n",
              " [126, 346]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert data to sequence of tokens\n",
        "input_sequences = []\n",
        "for line in all_headlines:\n",
        "    # Convert our headline into a sequence of tokens\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Create a series of sequences for each headline\n",
        "    for i in range(1, len(token_list)):\n",
        "        partial_sequence = token_list[:i+1]\n",
        "        input_sequences.append(partial_sequence)\n",
        "\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\n",
        "input_sequences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnIPaK7bt2kQ",
        "outputId": "0e4fa9d4-1a78-4561-ddf2-dfaf01fa2e7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,   52, 1616], dtype=int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Determine max sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IafWYk0tt2kR",
        "outputId": "0f2eabf6-92ea-40b9-eed3-1074ff065967"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1616,    1, 1992,  125,  346], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predictors are every word except the last\n",
        "predictors = input_sequences[:,:-1]\n",
        "# Labels are the last word\n",
        "labels = input_sequences[:,-1]\n",
        "labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x56D9W-Xt2kS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iIY6zN6t2kh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\n",
        "input_len = max_sequence_len - 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add input embedding layer\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "\n",
        "# Add LSTM layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VfWcM8_t2kh",
        "outputId": "719d230a-ebc8-4429-bcda-b586660298da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 10)            117530    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11753)             1187053   \n",
            "=================================================================\n",
            "Total params: 1,348,983\n",
            "Trainable params: 1,348,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URlSw98ht2kj"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3p9byLpLt2kk",
        "outputId": "194be517-6378-4207-d061-b1ebce53fe2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 7s 5ms/step - loss: 7.8844\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.4662\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.2597\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.0413\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.8059\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.5669\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.3289\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.0923\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.8652\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.6438\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.4327\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.2319\n",
            "Epoch 13/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.0396\n",
            "Epoch 14/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.8587\n",
            "Epoch 15/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.6898\n",
            "Epoch 16/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.5241\n",
            "Epoch 17/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.3712\n",
            "Epoch 18/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.2282\n",
            "Epoch 19/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.0919\n",
            "Epoch 20/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.9650\n",
            "Epoch 21/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.8485\n",
            "Epoch 22/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.7336\n",
            "Epoch 23/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.6284\n",
            "Epoch 24/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.5313\n",
            "Epoch 25/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.4410\n",
            "Epoch 26/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.3510\n",
            "Epoch 27/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.2669\n",
            "Epoch 28/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1915\n",
            "Epoch 29/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1173\n",
            "Epoch 30/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.0534\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd03cbf898>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(predictors, labels, epochs=30, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reT1055At2km"
      },
      "outputs": [],
      "source": [
        "def predict_next_token(seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    prediction = model.predict_classes(token_list, verbose=0)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ6018TFt2km",
        "outputId": "b90c0731-057c-4e9b-fae6-20d3aad881ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-bd91571ab9e2>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7010])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = predict_next_token(\"today in new york\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7FRlS7bt2kn",
        "outputId": "54195ddb-0323-4361-e3c4-4887b534cf7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['subway’s']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([prediction])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWGpxQl9t2ko"
      },
      "outputs": [],
      "source": [
        "def generate_headline(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        # Predict next token\n",
        "        prediction = predict_next_token(seed_text)\n",
        "        # Convert token to word\n",
        "        next_word = tokenizer.sequences_to_texts([prediction])[0]\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\n",
        "        seed_text += \" \" + next_word\n",
        "    # Return headline as title-case\n",
        "    return seed_text.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzfOdRURt2ko",
        "outputId": "2b42c097-7d15-4361-f07c-2ac6e3707fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Washington Dc Is A New Ground To Win\n",
            "Today In New York Subway’S Service And Straphangers Fuming\n",
            "The School District Has The President States Should Do\n",
            "Crime Has Become A Blow On A Second\n"
          ]
        }
      ],
      "source": [
        "seed_texts = [\n",
        "    'washington dc is',\n",
        "    'today in new york',\n",
        "    'the school district has',\n",
        "    'crime has become']\n",
        "for seed in seed_texts:\n",
        "    print(generate_headline(seed, next_words=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmzRg1zKt2kt",
        "outputId": "66efe88e-42f9-4fab-e243-ab51d66df827"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}